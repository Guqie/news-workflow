#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­å›½æœç´¢å…³é”®è¯æœç´¢æµ‹è¯• - è½»é‡çº§ç‰ˆæœ¬ï¼ˆrequests + BeautifulSoupï¼‰
"""

import requests
from bs4 import BeautifulSoup
import urllib.parse
import time

def test_chinaso_search_simple(keyword):
    """ä½¿ç”¨requestsæµ‹è¯•ä¸­å›½æœç´¢"""
    
    print(f"\n{'='*70}")
    print(f"æµ‹è¯•å…³é”®è¯: {keyword}")
    print('='*70)
    
    try:
        # æ„å»ºæœç´¢URL
        base_url = "https://www.chinaso.com/search/pagesearch.htm"
        params = {
            'q': keyword,
            'page': 1
        }
        
        search_url = f"{base_url}?{urllib.parse.urlencode(params)}"
        print(f"ğŸ” æœç´¢URL: {search_url}")
        
        # å‘é€è¯·æ±‚
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        print("ğŸ“¡ å‘é€è¯·æ±‚...")
        response = requests.get(search_url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        print(f"âœ… çŠ¶æ€ç : {response.status_code}")
        
        if response.status_code == 200:
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨
            selectors = [
                'div.news-item',
                'div.result',
                'div.item',
                'div[class*="result"]',
                'a[href*="http"]'
            ]
            
            results = []
            for selector in selectors:
                elements = soup.select(selector)
                if elements:
                    print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨: {selector}, æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ")
                    results = elements
                    break
            
            if results:
                print(f"\nğŸ“Š æœç´¢ç»“æœæ•°é‡: {len(results)}")
                print(f"\nå‰5ä¸ªç»“æœ:")
                
                for i, result in enumerate(results[:5], 1):
                    try:
                        # æå–æ ‡é¢˜å’Œé“¾æ¥
                        title = result.get_text(strip=True)[:80]
                        link = result.get('href', '')
                        
                        if title:
                            print(f"\n{i}. {title}")
                        if link:
                            print(f"   é“¾æ¥: {link}")
                    except:
                        continue
                
                return len(results)
            else:
                print("âš ï¸  æœªæ‰¾åˆ°æœç´¢ç»“æœ")
                print("\nğŸ“„ é¡µé¢å†…å®¹ç‰‡æ®µ:")
                print(response.text[:500])
                return 0
        else:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return 0
            
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 0

if __name__ == '__main__':
    # æµ‹è¯•å…³é”®è¯
    test_keywords = [
        "æˆ˜ç•¥æ–°å…´äº§ä¸š",
        "æ–°èƒ½æº",
        "äººå·¥æ™ºèƒ½"
    ]
    
    print("=" * 70)
    print("ä¸­å›½æœç´¢å…³é”®è¯æœç´¢æµ‹è¯•ï¼ˆè½»é‡çº§ç‰ˆæœ¬ï¼‰")
    print("=" * 70)
    
    results_summary = []
    
    for keyword in test_keywords:
        count = test_chinaso_search_simple(keyword)
        results_summary.append({
            'keyword': keyword,
            'count': count
        })
        time.sleep(2)
    
    # è¾“å‡ºæ±‡æ€»
    print("\n" + "=" * 70)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)
    
    for result in results_summary:
        status = "âœ…" if result['count'] > 0 else "âŒ"
        print(f"{status} {result['keyword']}: {result['count']} ä¸ªç»“æœ")
    
    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 70)
