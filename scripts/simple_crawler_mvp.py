#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MVPç‰ˆæœ¬ï¼šæœ€ç®€å•çš„æ–°é—»çˆ¬è™«
ä»ä¸­å›½æœç´¢æŠ“å–24å°æ—¶å†…çš„æ–°é—»
"""

import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime

def search_chinaso(keyword, max_results=10):
    """
    ä»ä¸­å›½æœç´¢è·å–æ–°é—»
    """
    print(f"\nğŸ” æ­£åœ¨æœç´¢å…³é”®è¯: {keyword}")
    print("=" * 60)
    
    # æ„é€ æœç´¢URL
    url = "https://www.chinaso.com/search/pagesearch.htm"
    params = {
        "q": keyword,
        "time": "1",  # 24å°æ—¶å†…
        "page": 1
    }
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        if response.status_code != 200:
            print(f"âŒ è¯·æ±‚å¤±è´¥: {response.status_code}")
            return []
        
        soup = BeautifulSoup(response.text, 'html.parser')
        results = []
        
        # è§£ææœç´¢ç»“æœï¼ˆéœ€è¦æ ¹æ®å®é™…é¡µé¢ç»“æ„è°ƒæ•´ï¼‰
        # è¿™é‡Œå…ˆç”¨é€šç”¨æ–¹æ³•æå–é“¾æ¥å’Œæ ‡é¢˜
        news_items = soup.find_all('a', href=True)
        
        count = 0
        for item in news_items:
            if count >= max_results:
                break
                
            title = item.get_text().strip()
            link = item.get('href', '')
            
            # ç®€å•è¿‡æ»¤
            if len(title) > 10 and 'http' in link:
                results.append({
                    'title': title,
                    'link': link
                })
                count += 1
        
        return results
        
    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±è´¥: {e}")
        return []

def main():
    """
    ä¸»å‡½æ•°ï¼šæµ‹è¯•çˆ¬å–æ•™è‚²å’ŒåŒ»ç–—æ–°é—»
    """
    print("\n" + "="*60)
    print("ğŸ“° æ–°é—»çˆ¬è™« MVP æµ‹è¯•")
    print(f"â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*60)
    
    # æ•™è‚²äººæ‰æ¿å—å…³é”®è¯
    education_keywords = ["æ•™è‚²æ”¿ç­–", "äººæ‰å¼•è¿›"]
    
    # åŒ»ç–—å¥åº·æ¿å—å…³é”®è¯
    healthcare_keywords = ["åŒ»ç–—æ”¿ç­–", "ç”Ÿç‰©åŒ»è¯"]
    
    print("\nğŸ“š æ•™è‚²äººæ‰æ¿å—")
    print("-"*60)
    for keyword in education_keywords:
        results = search_chinaso(keyword, max_results=5)
        for i, news in enumerate(results, 1):
            print(f"{i}. {news['title']}")
            print(f"   ğŸ”— {news['link']}\n")
        time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    
    print("\nğŸ¥ åŒ»ç–—å¥åº·æ¿å—")
    print("-"*60)
    for keyword in healthcare_keywords:
        results = search_chinaso(keyword, max_results=5)
        for i, news in enumerate(results, 1):
            print(f"{i}. {news['title']}")
            print(f"   ğŸ”— {news['link']}\n")
        time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    print("\n" + "="*60)
    print("âœ… æµ‹è¯•å®Œæˆï¼")
    print("="*60)

if __name__ == '__main__':
    main()
