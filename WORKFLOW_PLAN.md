# 新闻采集工作流规划

**规划时间：** 2026-02-09
**当前状态：** 采集系统优化完成

---

## 一、当前完成的工作

### ✅ 已完成
1. **通用爬虫开发**
   - 自动识别网页结构
   - 支持多页爬取
   - 智能关键词匹配
   - 智能去重机制

2. **Google搜索优化**
   - 扩充检索词到20个
   - 基于检索策略文档
   - 覆盖4大类别

3. **系统集成**
   - 替换滚动新闻爬虫
   - 配置可用信源
   - 测试验证通过

4. **数据效果**
   - 医疗健康：296条
   - 数据量提升139%

---

## 二、后续工作流程

### 阶段1：智能筛选（优先级：高）

**目标：** 从296条新闻中筛选出高质量新闻

**步骤：**
1. 运行智能筛选器
2. 设置筛选阈值
3. 人工审核筛选结果
4. 调整筛选参数

**预期产出：**
- 高质量新闻：30-50条
- 筛选准确率：>80%

**时间估计：** 1-2小时

---

### 阶段2：内容生成（优先级：高）

**目标：** 生成新闻简报

**步骤：**
1. 对筛选后的新闻进行分类
2. 生成新闻摘要
3. 生成新闻简报
4. 格式化输出

**预期产出：**
- 医疗健康简报（PDF/Markdown）
- 教育人才简报（PDF/Markdown）

**时间估计：** 1-2小时

---

### 阶段3：自动化部署（优先级：中）

**目标：** 设置定时任务

**步骤：**
1. 配置cron定时任务
2. 设置运行时间（工作日早上9点）
3. 配置通知机制
4. 测试自动化流程

**预期产出：**
- 每工作日自动运行
- 自动生成简报
- 自动发送通知

**时间估计：** 2-3小时

---

### 阶段4：优化迭代（优先级：低）

**目标：** 持续优化系统

**优化方向：**
1. 检索词优化
   - 根据实际效果调整
   - 移除低效检索词
   - 增加高效检索词

2. 筛选算法优化
   - 提高准确率
   - 降低误判率

3. 新增数据源
   - 探索新的可用网站
   - 增加RSS源

4. 性能优化
   - 提高爬取速度
   - 优化去重算法

**时间估计：** 持续进行

---

## 三、立即可执行的任务

### 任务1：运行智能筛选
```bash
cd /root/clawd/news-workflow/scripts
python3 news_filter.py --sector healthcare --input ../data/raw/healthcare_aggregated_20260209.json
```

### 任务2：测试教育人才板块
```bash
cd /root/clawd/news-workflow/scripts
python3 news_aggregator.py --sector education --hours 24
```

### 任务3：生成新闻简报
```bash
cd /root/clawd/news-workflow/scripts
python3 news_reporter.py --sector healthcare --date 20260209
```

---

## 四、工作流程图

```
每工作日 09:00
    ↓
运行新闻聚合器
    ↓
Google搜索（20个检索词）+ 通用爬虫（4个网站）
    ↓
采集300+条新闻
    ↓
智能筛选
    ↓
保留30-50条高质量新闻
    ↓
生成新闻简报
    ↓
发送通知/邮件
```

---

## 五、下一步建议

**立即执行：**
1. ✅ 运行智能筛选（查看筛选效果）
2. ✅ 测试教育人才板块（验证完整性）

**短期计划（本周）：**
3. 生成新闻简报
4. 设置定时任务

**长期计划（本月）：**
5. 优化检索词
6. 新增数据源
7. 性能优化
